{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94b02223-beaf-4dc6-93c2-928a9a6fed00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m184 packages\u001b[0m \u001b[2min 167ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m150 packages\u001b[0m \u001b[2min 0.05ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add PyPDF2 --native-tls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfc4e9ce-925a-4cc8-9fd8-a0efe6c6cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "with open(\"/Users/ragulasaikumar/Downloads/crime-and-punishment.pdf\",'rb') as pdf_file:\n",
    "    pdf_reader=PyPDF2.PdfReader(pdf_file)\n",
    "    text=\"\"\n",
    "    page_num=0\n",
    "    for page in pdf_reader.pages:\n",
    "        if page_num>=6 and page_num<=10:\n",
    "            curr_page_text=page.extract_text()\n",
    "            text+=curr_page_text\n",
    "        page_num+=1\n",
    "heading_pattern='\\d* Free eBooks at Planet eBook\\.com|Crime and Punishment\\s*\\d*'\n",
    "text=re.sub(heading_pattern,'',text)\n",
    "text=re.sub('Chapter [A-Z]{1,3}','',text)\n",
    "text=text.replace(' -\\n','').replace(\"\\n\",\"\").replace('\\x18','')\n",
    "text=text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d15895f2-6c1c-4379-ae03-b451f20ba841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "preprocess_pipeline=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45f91bea-fbcd-4fd4-a912-ead219ad5165",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=preprocess_pipeline(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "812d5fdd-33ee-4b68-b251-381f071d9bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab={'<UNKNOWN>':0}\n",
    "dataset=map(lambda sent:list(sent),list(doc.sents))\n",
    "tokenized_sentences=list(dataset)\n",
    "io_pairs=[]\n",
    "for tokens in tokenized_sentences:\n",
    "    for i in range(1,len(tokens)):\n",
    "        io_pairs.append(tokens[:i+1])\n",
    "\n",
    "for i,datapoint in enumerate(io_pairs):\n",
    "    for j,token in enumerate(datapoint):\n",
    "        token=str(token)\n",
    "        if vocab.get(token)==None:\n",
    "            vocab[token]=len(vocab)\n",
    "        io_pairs[i][j]=vocab[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "843bcec9-b3c2-45bb-a344-db172d5843b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.tensor(io_pairs[1])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a31401e1-92eb-46b7-87b5-103467859c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43ede854-6d9b-4a00-8450-f085e9b40f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookDataSet(Dataset):\n",
    "    def __init__(self,dataset):\n",
    "        self.data=dataset\n",
    "    def __getitem__(self,idx):\n",
    "        X=torch.tensor(self.data[idx])[:-1]\n",
    "        Y=torch.tensor(self.data[idx])[-1]\n",
    "        return X,Y\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "dataloader=DataLoader(dataset=BookDataSet(io_pairs),batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c961f374-b6d6-4c78-8e7c-d99357c894f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class NextWordPredictor(nn.Module):\n",
    "    def __init__(self,vocab_size,hidden_layer_neurons):\n",
    "        super().__init__()\n",
    "        self.embedding_layer=nn.Embedding(vocab_size,hidden_layer_neurons)\n",
    "        self.lstm=nn.LSTM(hidden_layer_neurons,hidden_layer_neurons,batch_first=True)\n",
    "        self.fc=nn.Linear(hidden_layer_neurons,vocab_size)\n",
    "    def forward(self,_input):\n",
    "        embeddings=self.embedding_layer(_input)\n",
    "        intermediate_hidden_states, (final_hidden_state, final_cell_state)=self.lstm(embeddings)\n",
    "        return self.fc(final_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4efff6e-a095-4e96-94da-ab0210d5c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "# if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "predictor=NextWordPredictor(len(vocab),64).to(device)\n",
    "criterion=CrossEntropyLoss()\n",
    "optimizer=AdamW(params=predictor.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f5feb84-7a47-415b-b4f4-c01719b933ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 4.557296276092529\n",
      "Loss : 6.731215000152588\n",
      "Loss : 7.513824462890625\n",
      "Loss : 1.3990260362625122\n",
      "Loss : 2.386157751083374\n",
      "Loss : 0.039390306919813156\n",
      "Loss : 5.336611747741699\n",
      "Loss : 1.0489188432693481\n",
      "Loss : 3.49109148979187\n",
      "Loss : 0.8178143501281738\n",
      "Loss : 1.5251140594482422\n",
      "Loss : 0.7690956592559814\n",
      "Loss : 0.07181935012340546\n",
      "Loss : 0.16466552019119263\n",
      "Loss : 0.22970281541347504\n",
      "Loss : 2.9346799850463867\n",
      "Loss : 0.08589158207178116\n",
      "Loss : 0.04339710623025894\n",
      "Loss : 0.1583336889743805\n",
      "Loss : 0.08999300748109818\n",
      "Loss : 0.025081543251872063\n",
      "Loss : 0.05106295645236969\n",
      "Loss : 0.020524965599179268\n",
      "Loss : 0.01177067682147026\n",
      "Loss : 0.08231039345264435\n",
      "Loss : 0.030689697712659836\n",
      "Loss : 0.012684616260230541\n",
      "Loss : 0.007025657221674919\n",
      "Loss : 0.0033400245010852814\n",
      "Loss : 0.011088653467595577\n",
      "Loss : 0.007412785664200783\n",
      "Loss : 0.010228240862488747\n",
      "Loss : 0.004220032598823309\n",
      "Loss : 0.024098344147205353\n",
      "Loss : 0.005129747558385134\n",
      "Loss : 0.006055105477571487\n",
      "Loss : 0.017625020816922188\n",
      "Loss : 0.0012054328108206391\n",
      "Loss : 0.007593339309096336\n",
      "Loss : 0.0239041019231081\n",
      "Loss : 0.0050104293040931225\n",
      "Loss : 0.04205658286809921\n",
      "Loss : 0.003720506327226758\n",
      "Loss : 0.07658406347036362\n",
      "Loss : 0.0033784001134335995\n",
      "Loss : 0.003065056400373578\n",
      "Loss : 0.04052562639117241\n",
      "Loss : 0.0020920787937939167\n",
      "Loss : 0.008801357820630074\n",
      "Loss : 0.1846245527267456\n"
     ]
    }
   ],
   "source": [
    "epochs=50\n",
    "for epoch in range(epochs):\n",
    "    for features,output in dataloader:\n",
    "        features=features.to(device)\n",
    "        output=output.to(device)\n",
    "        y_pred=predictor(features)\n",
    "        loss=criterion(y_pred.squeeze(1),output)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Loss : {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3cdd9d30-e43a-4575-80c7-8a6e86119dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"It would be\".lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "426cc2c3-4c85-4a03-bbb5-77cd4c8b5bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it would be interesting\n",
      "it would be interesting to\n",
      "it would be interesting to know\n",
      "it would be interesting to know what\n",
      "it would be interesting to know what it\n",
      "it would be interesting to know what it is\n",
      "it would be interesting to know what it is men\n",
      "it would be interesting to know what it is men are\n",
      "it would be interesting to know what it is men are most\n",
      "it would be interesting to know what it is men are most afraid\n",
      "it would be interesting to know what it is men are most afraid of\n",
      "it would be interesting to know what it is men are most afraid of .\n",
      "it would be interesting to know what it is men are most afraid of . taking\n",
      "it would be interesting to know what it is men are most afraid of . taking a\n",
      "it would be interesting to know what it is men are most afraid of . taking a new\n",
      "it would be interesting to know what it is men are most afraid of . taking a new step\n",
      "it would be interesting to know what it is men are most afraid of . taking a new step ,\n",
      "it would be interesting to know what it is men are most afraid of . taking a new step , uttering\n",
      "it would be interesting to know what it is men are most afraid of . taking a new step , uttering a\n",
      "it would be interesting to know what it is men are most afraid of . taking a new step , uttering a new\n",
      "it would be interesting to know what it is men are most afraid of . taking a new step , uttering a new word\n",
      "it would be interesting to know what it is men are most afraid of . taking a new step , uttering a new word is\n",
      "it would be interesting to know what it is men are most afraid of . taking a new step , uttering a new word is what\n",
      "it would be interesting to know what it is men are most afraid of . taking a new step , uttering a new word is what they\n",
      "it would be interesting to know what it is men are most afraid of . taking a new step , uttering a new word is what they fear\n",
      "it would be interesting to know what it is men are most afraid of . taking a new step , uttering a new word is what they fear most\n",
      "it would be interesting to know what it is men are most afraid of . taking a new step , uttering a new word is what they fear most …\n",
      "it would be interesting to know what it is men are most afraid of . taking a new step , uttering a new word is what they fear most … .\n",
      "it would be interesting to know what it is men are most afraid of . taking a new step , uttering a new word is what they fear most … . .\n",
      "it would be interesting to know what it is men are most afraid of . taking a new step , uttering a new word is what they fear most … . . taking\n"
     ]
    }
   ],
   "source": [
    "predictor.eval()\n",
    "for i in range(30):\n",
    "    tokens=list(map(lambda text_tok:vocab[text_tok],text.split(\" \")))\n",
    "    next_token=predictor(torch.tensor(tokens))\n",
    "    token_ind=torch.argmax(next_token)\n",
    "    text_token=list(vocab.keys())[token_ind]\n",
    "    text+=f\" {text_token}\"\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "89cc37d5-a73b-4960-8dd3-6b91c60fa0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e1e7d3-e5eb-4ed2-a186-fe24605b9a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
